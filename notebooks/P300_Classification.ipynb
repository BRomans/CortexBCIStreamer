{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Classification\n",
    "\n",
    "### Load Libraries and Data\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be07a6b1610fbc8a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from mne import find_events\n",
    "from utils.loader import load_data, unicorn_fs, unicorn_channels, convert_to_mne\n",
    "from utils.preprocessing import extract_epochs, extract_events\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from utils.validation import plot_confusion_matrix, plot_cross_validated_confusion_matrix\n",
    "\n",
    "eeg, trigger = load_data(\"../data/aep/auditory_erp_eyes_open_S1.csv\", header=False, fs=unicorn_fs, skiprows=5)\n",
    "print(\"Loaded data with shape:\" + str(eeg.shape) + \" and trigger shape: \" + str(trigger.shape))\n",
    "print(\"That means we have \" + str(eeg.shape[0]) + \" samples and \" + str(eeg.shape[1]) + \" channels.\")\n",
    "\n",
    " # Convert to MNE format\n",
    "raw_data = convert_to_mne(eeg, trigger, fs=unicorn_fs, chs=unicorn_channels, recompute=False) # recompute=True to recalculate the event labels if the values are negative"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1c5ccfc018f7f11",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Preparation\n",
    "\n",
    "\n",
    "1. Extract events and event ids  \n",
    "2. Epoching and baseline correction\n",
    "3. Resample and split the data\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd7d4b3015f3fcc1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.Extract events and event ids"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "268919f32bbdd7dd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ev_ids = {'NT': 2, 'T':1}\n",
    "event_colors = {2:'r', 1:'g'}\n",
    "stim_channel = 'STI'\n",
    "events = find_events(raw_data, stim_channel=stim_channel)\n",
    "raw_data.plot(events=events, event_id=ev_ids, event_color=event_colors, color = 'Gray', block = True, clipping=None, scalings=25e-6)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "911efbe6c15901a2",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.Epoching with baseline correction\n",
    "The baseline segment is defined as the interval before the onset of the event. The mean of this interval is subtracted from the entire epoch to correct for the baseline shift."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5426632c3aa1054d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "baseline=(-.6, 0) \n",
    "eps = extract_epochs(data=raw_data, events=events, ev_ids=ev_ids, tmin=-0.6, tmax=0.8, baseline=baseline)\n",
    "eps.apply_baseline(baseline)\n",
    "\n",
    "X = eps.get_data(picks='eeg')[:, :, 150:350]\n",
    "\n",
    "y = eps.events[:,-1]\n",
    "\n",
    "print(X.shape, y.shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f29a662672ae741",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.Resample and split the data\n",
    "There main reason for resampling the data is to avoid unbalanced classes. The number of samples in the minority class is much lower than the majority class. \n",
    "This can lead to a model that is biased towards the majority class. \n",
    "To avoid this, we can oversample the minority class or undersample the majority class (or both!)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "671f92bd3201ffab"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "random_state = 32\n",
    "\n",
    "# Oversampling the minority class and undersampling the majority class\n",
    "oversampler = RandomOverSampler(sampling_strategy='minority', random_state=random_state)\n",
    "undersampler = RandomUnderSampler(sampling_strategy=0.4, random_state=random_state)\n",
    "\n",
    "\n",
    "\n",
    "# Assuming you have epochs of size (1, 8, 200)\n",
    "num_epochs = len(X)\n",
    "epoch_size = (1, 8, 200)\n",
    "\n",
    "# Reshape the data for LDA\n",
    "X_r = X.reshape(num_epochs, -1)\n",
    "y_r = y\n",
    "X_r, y_r = oversampler.fit_resample(X_r, y) # Uncomment this line to oversample the minority class\n",
    "#X_r, y_r = undersampler.fit_resample(X_r, y) # Uncomment this line to undersample the majority class\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_r, y_r, test_size=0.2, random_state=33)\n",
    "print(X_train.shape, X_test.shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ec7667c95f74308",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Classification\n",
    "1. Linear Discriminant Analysis\n",
    "2. Cross-Validation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f967ed2102693bc7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.LinearDiscriminantAnalysis\n",
    "For classification, we use LDA, a model that fits a Gaussian density for each class and has been shown to be a good classifier for ERP data in previous studies [1].\n",
    "Other classifiers can be used, such as SVM, or variants of LDA such as QDA.\n",
    "[1] D. J. Krusienski et al., “A comparison of classification techniques for the P300 Speller,” J Neural Eng, vol. 3, no. 4, pp. 299–305, Dec. 2006, doi: 10.1088/1741-2560/3/4/007.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "966458a803b5d885"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# Apply LDA\n",
    "model = LinearDiscriminantAnalysis()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='binary')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f} F1 Score: {f1:.2f}')\n",
    "plot_confusion_matrix(y_test, y_pred, classes=['Target', 'Non-Target'], normalize=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc3b754c1d131d0e",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.Cross-Validation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dfdff6c50fb0168f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Use cross-validation\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(model, X_r, y_r, cv=cv)\n",
    "f1 = cross_val_score(model, X_r, y_r, cv=cv, scoring='f1', error_score=0)\n",
    "\n",
    "\n",
    "# Print cross-validated accuracy\n",
    "print(f'Cross-validated accuracy: {np.mean(scores):.2f} (+/- {np.std(scores):.2f}) F1-Score: {np.mean(f1):.2f}')\n",
    "\n",
    "plot_cross_validated_confusion_matrix(X_r, y_r, model, cv=cv, classes=['Target', 'Non-Target'], normalize=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf7690e81696455f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1f4896438d608128"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
